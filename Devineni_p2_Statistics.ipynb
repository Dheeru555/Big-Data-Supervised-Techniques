{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used basic statistics and data manipulation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SparkSession is the entry point to Spark SQL. It is the very first object \n",
    "#to create while developing Spark SQL applications.\n",
    "#Used the SparkSession.builder method to create an instance of SparkSession with appName('WorldHealthRprt')\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('WorldHealthRprt').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the three csv files(WH_2015,WH_2016,WH_2017) into a three dataframes i.e. df1,df2 & df3.\n",
    "df1 = spark.read.csv ('WH_2015.csv', inferSchema=True, header =True)\n",
    "df2 = spark.read.csv ('WH_2016.csv', inferSchema=True, header =True)\n",
    "df3 = spark.read.csv ('WH_2017.csv', inferSchema=True, header =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Happiness Rank: integer (nullable = true)\n",
      " |-- Happiness Score: double (nullable = true)\n",
      " |-- Standard Error: double (nullable = true)\n",
      " |-- Economy (GDP per Capita): double (nullable = true)\n",
      " |-- Family: double (nullable = true)\n",
      " |-- Health (Life Expectancy): double (nullable = true)\n",
      " |-- Freedom: double (nullable = true)\n",
      " |-- Trust (Government Corruption): double (nullable = true)\n",
      " |-- Generosity: double (nullable = true)\n",
      " |-- Dystopia Residual: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To show the schema of the dataframe df1\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new Dataframe 'df_2015' which contains only selected columns from df1(WH_2015 data) dataframe like Country,Happiness Rank \n",
    "#& Region columns and sorting them based on 'Country' in ascending order.\n",
    "#Last three steps renaming the column names from ('Country','Happiness Rank','Region') to ('Country_2015','HR_2015','Region_2015')\n",
    "df_2015 = df1.select(['Country','Happiness Rank','Region']).sort('Country')\n",
    "df_2015 = df_2015.withColumnRenamed(\"Happiness Rank\", \"HR_2015\")\n",
    "df_2015 = df_2015.withColumnRenamed(\"Country\", \"Country_2015\")\n",
    "df_2015 = df_2015.withColumnRenamed(\"Region\", \"Region_2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Happiness Rank: integer (nullable = true)\n",
      " |-- Happiness Score: double (nullable = true)\n",
      " |-- Lower Confidence Interval: double (nullable = true)\n",
      " |-- Upper Confidence Interval: double (nullable = true)\n",
      " |-- Economy (GDP per Capita): double (nullable = true)\n",
      " |-- Family: double (nullable = true)\n",
      " |-- Health (Life Expectancy): double (nullable = true)\n",
      " |-- Freedom: double (nullable = true)\n",
      " |-- Trust (Government Corruption): double (nullable = true)\n",
      " |-- Generosity: double (nullable = true)\n",
      " |-- Dystopia Residual: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To show the schema of the dataframe df2\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new Dataframe 'df_2016' which contains only selected columns from df2(WH_2016 data) dataframe like Country,Happiness Rank \n",
    "#& Region columns and sorting them based on 'Country' in ascending order.\n",
    "#Last three steps renaming the column names from ('Country','Happiness Rank','Region') to ('Country_2016','HR_2016','Region_2016')\n",
    "df_2016 = df2.select(['Country','Happiness Rank','Region']).sort('Country')\n",
    "df_2016 = df_2016.withColumnRenamed(\"Happiness Rank\", \"HR_2016\")\n",
    "df_2016 = df_2016.withColumnRenamed(\"Country\", \"Country_2016\")\n",
    "df_2016 = df_2016.withColumnRenamed(\"Region\", \"Region_2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Happiness.Rank: integer (nullable = true)\n",
      " |-- Happiness.Score: double (nullable = true)\n",
      " |-- Whisker.high: double (nullable = true)\n",
      " |-- Whisker.low: double (nullable = true)\n",
      " |-- Economy..GDP.per.Capita.: double (nullable = true)\n",
      " |-- Family: double (nullable = true)\n",
      " |-- Health..Life.Expectancy.: double (nullable = true)\n",
      " |-- Freedom: double (nullable = true)\n",
      " |-- Generosity: double (nullable = true)\n",
      " |-- Trust..Government.Corruption.: double (nullable = true)\n",
      " |-- Dystopia.Residual: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To show the schema of the dataframe df2\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the regularExpression module or function\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the column names in df3 with any dots('.') with '_' and placing it new dataframe 'df_test'\n",
    "#I'm doing it as in pyspark it will not take or consider any dots in column name specification, so replacing with '_'.\n",
    "df_test = df3.toDF(*(re.sub(r'[\\.\\s]+', '_', c) for c in df3.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Happiness_Rank: integer (nullable = true)\n",
      " |-- Happiness_Score: double (nullable = true)\n",
      " |-- Whisker_high: double (nullable = true)\n",
      " |-- Whisker_low: double (nullable = true)\n",
      " |-- Economy_GDP_per_Capita_: double (nullable = true)\n",
      " |-- Family: double (nullable = true)\n",
      " |-- Health_Life_Expectancy_: double (nullable = true)\n",
      " |-- Freedom: double (nullable = true)\n",
      " |-- Generosity: double (nullable = true)\n",
      " |-- Trust_Government_Corruption_: double (nullable = true)\n",
      " |-- Dystopia_Residual: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To show the schema of the dataframe df_test\n",
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new Dataframe 'df_2017' which contains only selected columns from df_test(WH_2017 data) dataframe like Country,Happiness Rank \n",
    "#columns and sorting them based on 'Country' in ascending order.\n",
    "#Last two steps renaming the column names from ('Country','Happiness_Rank') to ('Country_2017','HR_2017')\n",
    "df_2017 = df_test.select(['Country','Happiness_Rank']).sort('Country')\n",
    "df_2017 = df_2017.withColumnRenamed(\"Happiness_Rank\", \"HR_2017\")\n",
    "df_2017 = df_2017.withColumnRenamed(\"Country\", \"Country_2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all modules or functions from subpackage sql.functions\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making alias for dataframes df_2015 & df_2016 with names df_2015_1 & df_2016_1\n",
    "#Using this alias names in joining tables for refering the keys that is involved.\n",
    "df_2015 = df_2015.alias(\"df_2015_1\")\n",
    "df_2016 = df_2016.alias(\"df_2016_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing here full outer join on dataframes df_2015 & df_2016, so as not to miss any data on the key field 'Country' i.e\n",
    "#Country_2015 & Country_2016 and placing the result in new dataframe 'join'\n",
    "join = df_2015.join(df_2016, col(\"df_2015_1.Country_2015\") == col(\"df_2016_1.Country_2016\"),'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It will show the count or number of rows present in the dataframe join.\n",
    "join.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column name 'Country_1' to maintain global country names from the year wh_2015 & wh_2016\n",
    "#I'm using the function 'coalesce' it will merge the two columns country names into one, where if you have null it will replace \n",
    "#the contents from one of those columns(WH_2015, WH_2016) that don't have null value. If both have null content then it will\n",
    "#replace the word 'Not_Available' in new Country_1 column and placing into new dataframe 'join1'\n",
    "join1 = join.withColumn('Country_1',coalesce(join[\"Country_2015\"],join[\"Country_2016\"], lit(\"Not_Avaiable\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country_2015: string (nullable = true)\n",
      " |-- HR_2015: integer (nullable = true)\n",
      " |-- Region_2015: string (nullable = true)\n",
      " |-- Country_2016: string (nullable = true)\n",
      " |-- HR_2016: integer (nullable = true)\n",
      " |-- Region_2016: string (nullable = true)\n",
      " |-- Country_1: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To show the schema of the dataframe join1\n",
    "join1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making alias for dataframes df_2017 & join1(df_2015 & df_2016 data) with names df_2017_1 & join_1\n",
    "#Using this alias names in joining tables for refering the keys that is involved.\n",
    "df_2017 = df_2017.alias(\"df_2017_1\")\n",
    "join1 = join1.alias(\"join_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing here full outer join on dataframes df_2017 & join1, so as not to miss any data on the key field 'Country' i.e\n",
    "#Country_2017 & Country_1 and placing the result in new dataframe 'Final_join'\n",
    "Final_join = join1.join(df_2017, col(\"join_1.Country_1\") == col(\"df_2017_1.Country_2017\"),'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It will show the count or number of rows present in the dataframe Final_join.\n",
    "Final_join.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column name 'Country' to maintain global country names from df_2017 & Final_join\n",
    "#I'm using the function 'coalesce' it will merge the two columns country names into one, where if you have null it will replace \n",
    "#the contents from one of those columns(WH_2017, final_join) that don't have null value. If both have null content then it will\n",
    "#replace the word 'Not_Available' in new Country column and placing into new dataframe 'join2'\n",
    "join2 = Final_join.withColumn('Country',coalesce(Final_join[\"Country_1\"],Final_join[\"Country_2017\"], lit(\"Not_Available\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new Dataframe 'Last' which contains only selected columns from join2 dataframe like Country,HR_2015,HR_2016 & HR_2017\n",
    "Last = join2.select(['Country','HR_2015','HR_2016','HR_2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling any values with value zero and placing it in new dataframe 'Final'\n",
    "Final = Last.na.fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1) Gives Happiness Ranking that increased the most from 2015 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here filtering the ranks where HR_2015 is less than HR_2017 and discarding the rows whose happiness ranks are zero in the year 2015,2016 & 2017\n",
    "#Creating a new column diff, it will store the difference of two ranks i.e(HR_2017 - HR_2015) and places it in Increased_rnk dataframe.\n",
    "Increased_rnk = Final.filter((Final['HR_2015'] < Final['HR_2017']) & ~(Final['HR_2015'] == '0') & ~(Final['HR_2016'] == '0') & ~(Final['HR_2017'] == '0')).withColumn('diff',Final.HR_2017 - Final.HR_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+----+\n",
      "|   Country|HR_2015|HR_2016|HR_2017|diff|\n",
      "+----------+-------+-------+-------+----+\n",
      "| Venezuela|     23|     44|     82|  59|\n",
      "|   Liberia|    116|    150|    148|  32|\n",
      "|    Zambia|     85|    106|    116|  31|\n",
      "|     Haiti|    119|    136|    145|  26|\n",
      "|  Zimbabwe|    115|    131|    138|  23|\n",
      "|   Ukraine|    111|    123|    132|  21|\n",
      "|Kyrgyzstan|     77|     85|     98|  21|\n",
      "|   Vietnam|     75|     96|     94|  19|\n",
      "|    Bhutan|     79|     84|     97|  18|\n",
      "|  Paraguay|     53|     70|     70|  17|\n",
      "|   Nigeria|     78|    103|     95|  17|\n",
      "|     Ghana|    114|    124|    131|  17|\n",
      "|   Croatia|     62|     74|     77|  15|\n",
      "|  Botswana|    128|    137|    142|  14|\n",
      "|   Albania|     95|    109|    109|  14|\n",
      "|     Sudan|    118|    133|    130|  12|\n",
      "|    Mexico|     14|     21|     25|  11|\n",
      "|   Jamaica|     65|     73|     76|  11|\n",
      "|     Yemen|    136|    147|    146|  10|\n",
      "|    Kosovo|     69|     77|     78|   9|\n",
      "+----------+-------+-------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displays the result on sorting based on diff in descending order\n",
    "Increased_rnk.sort(desc(\"diff\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|   Country|\n",
      "+----------+\n",
      "| Venezuela|\n",
      "|   Liberia|\n",
      "|    Zambia|\n",
      "|     Haiti|\n",
      "|  Zimbabwe|\n",
      "|   Ukraine|\n",
      "|Kyrgyzstan|\n",
      "|   Vietnam|\n",
      "|    Bhutan|\n",
      "|   Nigeria|\n",
      "|  Paraguay|\n",
      "|     Ghana|\n",
      "|   Croatia|\n",
      "|  Botswana|\n",
      "|   Albania|\n",
      "|     Sudan|\n",
      "|    Mexico|\n",
      "|   Jamaica|\n",
      "|     Yemen|\n",
      "|    Kosovo|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displays the country's happiness ranking that increased the most.\n",
    "Increased_rnk.sort(desc(\"diff\")).select(['Country']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2) Gives Happiness Ranking that decreased the most from 2015 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here filtering the ranks where HR_2015 is greater than HR_2017 and discarding the rows whose happiness ranks are zero in the year 2015,2016 & 2017\n",
    "#Creating a new column diff, it will store the difference of two ranks i.e(HR_2015 - HR_2016) and places it in Decreased_rnk dataframe.\n",
    "Decreased_rnk = Final.filter((Final['HR_2015'] > Final['HR_2017']) & ~(Final['HR_2015'] == '0') & ~(Final['HR_2016'] == '0') & ~(Final['HR_2017'] == '0')).withColumn('diff',Final.HR_2015 - Final.HR_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+-------+----+\n",
      "|            Country|HR_2015|HR_2016|HR_2017|diff|\n",
      "+-------------------+-------+-------+-------+----+\n",
      "|             Latvia|     89|     68|     54|  35|\n",
      "|              Egypt|    135|    120|    104|  31|\n",
      "|            Hungary|    104|     91|     75|  29|\n",
      "|            Romania|     86|     71|     57|  29|\n",
      "|           Bulgaria|    134|    129|    105|  29|\n",
      "|            Senegal|    142|    128|    115|  27|\n",
      "|           Cameroon|    133|    114|    107|  26|\n",
      "|              Gabon|    143|    134|    118|  25|\n",
      "|        Ivory Coast|    151|    139|    128|  23|\n",
      "|              Nepal|    121|    107|     99|  22|\n",
      "|           Malaysia|     61|     47|     42|  19|\n",
      "|       Burkina Faso|    152|    145|    134|  18|\n",
      "|        Philippines|     90|     82|     72|  18|\n",
      "|       Sierra Leone|    123|    111|    106|  17|\n",
      "|           Cambodia|    145|    140|    129|  16|\n",
      "|            Myanmar|    129|    119|    114|  15|\n",
      "|            Algeria|     68|     38|     53|  15|\n",
      "|Congo (Brazzaville)|    139|    127|    124|  15|\n",
      "|            Lebanon|    103|     93|     88|  15|\n",
      "|             Russia|     64|     56|     49|  15|\n",
      "+-------------------+-------+-------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displays the result on sorting based on diff in descending order\n",
    "Decreased_rnk.sort(desc(\"diff\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|            Country|\n",
      "+-------------------+\n",
      "|             Latvia|\n",
      "|              Egypt|\n",
      "|            Hungary|\n",
      "|           Bulgaria|\n",
      "|            Romania|\n",
      "|            Senegal|\n",
      "|           Cameroon|\n",
      "|              Gabon|\n",
      "|        Ivory Coast|\n",
      "|              Nepal|\n",
      "|           Malaysia|\n",
      "|        Philippines|\n",
      "|       Burkina Faso|\n",
      "|       Sierra Leone|\n",
      "|           Cambodia|\n",
      "|            Algeria|\n",
      "|Congo (Brazzaville)|\n",
      "|            Myanmar|\n",
      "|             Greece|\n",
      "|            Lebanon|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displays the country's happiness ranking that decreased the most.\n",
    "Decreased_rnk.sort(desc(\"diff\")).select(['Country']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_2017.alias(\"df_2017_2\")\n",
    "join2 = join2.alias(\"join_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing inner join on df_2017 dataframe & join2 dataframe to get the regions for the df_2017 data and dropping off the 'HR_2017, which is duplicate column'\n",
    "joiner = df_2017.join(join2, col(\"df_2017_2.Country_2017\") == col(\"join_2.Country\"),'inner').drop(df_2017['HR_2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the required columns ['Country','HR_2017','Region_2015','Region_2016'] from the joiner dataframe into Final_joiner dataframe.\n",
    "Final_joiner = joiner.select(['Country','HR_2017','Region_2015','Region_2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----------+--------------------+\n",
      "|             Country|HR_2017|Region_2015|         Region_2016|\n",
      "+--------------------+-------+-----------+--------------------+\n",
      "|             Somalia|     93|       null|  Sub-Saharan Africa|\n",
      "|Taiwan Province o...|     33|       null|                null|\n",
      "|Hong Kong S.A.R.,...|     71|       null|                null|\n",
      "|             Namibia|    111|       null|  Sub-Saharan Africa|\n",
      "|         South Sudan|    147|       null|  Sub-Saharan Africa|\n",
      "|              Belize|     50|       null|Latin America and...|\n",
      "+--------------------+-------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To display null regions for the year 2015\n",
    "Final_joiner.where(col('Region_2015').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the new column 'Region_2017', by using the coalsce function on 2015,2016 regions to populate the region for 2017\n",
    "#If it is not present for corresponding country it will replace with 'Not Available'\n",
    "Converter = Final_joiner.withColumn('Region_2017',coalesce(Final_joiner[\"Region_2015\"],Final_joiner[\"Region_2016\"], lit(\"Not_Available\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = false)\n",
      " |-- HR_2017: integer (nullable = true)\n",
      " |-- Region_2015: string (nullable = true)\n",
      " |-- Region_2016: string (nullable = true)\n",
      " |-- Region_2017: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displays the schema of a Converter dataframe.\n",
    "Converter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting required fields like 'Country','HR_2017','Region_2017' for the year 2017 data and placing in in Doer_2017 data.\n",
    "Doer_2017 = Converter.select(['Country','HR_2017','Region_2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here grouping based on Region and calculating avg or mean on HR_Ranks and placing it in new dataframes\n",
    "#for all years 2015,2016 & 2017\n",
    "df_2015_R = df_2015.groupBy(\"Region_2015\").agg(avg(col(\"HR_2015\"))).alias('HR_2015')\n",
    "df_2015_CR = df_2015_R.sort(\"Region_2015\")\n",
    "df_2016_R = df_2016.groupBy(\"Region_2016\").agg(avg(col(\"HR_2016\"))).alias('HR_2016')\n",
    "df_2016_CR = df_2016_R.sort(\"Region_2016\")\n",
    "df_2017_R = Doer_2017.groupBy(\"Region_2017\").agg(avg(col(\"HR_2017\"))).alias('HR_2017')\n",
    "df_2017_CR = df_2017_R.sort(\"Region_2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making table alias for dataframes df_2015_CR & df_2016_CR for joining purpose.\n",
    "df_2015_CR = df_2015_CR.alias(\"df_2015_CR1\")\n",
    "df_2016_CR = df_2016_CR.alias(\"df_2016_CR1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing outer join on df_2015_CR & df_2016_CR dataframes on region as a key and dropping of 2016_region which is duplicate one.\n",
    "df_CR = df_2015_CR.join(df_2016_CR, col(\"df_2015_CR1.Region_2015\") == col(\"df_2016_CR1.Region_2016\"),'outer').drop(df_2016_CR['Region_2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making table alias for dataframes df_CR & df_2017_CR for joining purpose.\n",
    "df_CR = df_CR.alias(\"df_CR1\")\n",
    "df_2017_CR = df_2017_CR.alias(\"df_2017_CR1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing outer join on df_2017_CR & df_CR dataframes on region as a key and dropping of 2015_region which is duplicate one.\n",
    "df_CR_last = df_CR.join(df_2017_CR, col(\"df_CR1.Region_2015\") == col(\"df_2017_CR1.Region_2017\"),'outer').drop(df_CR['Region_2015'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3) Provide the ranking of the happiest continents for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the selected columns into meaning full one as specified below.\n",
    "df_CR_last = df_CR_last.withColumnRenamed(\"Region_2017\", \"Continent\")\n",
    "df_CR_last = df_CR_last.withColumnRenamed(\"avg(HR_2017)\", \"Mean_HR_2017\")\n",
    "df_CR_last = df_CR_last.withColumnRenamed(\"avg(HR_2016)\", \"Mean_HR_2016\")\n",
    "df_CR_last = df_CR_last.withColumnRenamed(\"avg(HR_2015)\", \"Mean_HR_2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It will fill if we have nulls in the data and places in new dataframe 'Continent_Ranking'\n",
    "Continent_Ranking = df_CR_last.na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+------------------+\n",
      "|           Continent|      Mean_HR_2015|      Mean_HR_2016|      Mean_HR_2017|\n",
      "+--------------------+------------------+------------------+------------------+\n",
      "|  Sub-Saharan Africa|             127.9| 129.6578947368421|127.87179487179488|\n",
      "|       Southern Asia|113.14285714285714|111.71428571428571|109.85714285714286|\n",
      "|   Southeastern Asia| 81.22222222222223|              80.0|             73.75|\n",
      "|Central and Easte...|              79.0| 78.44827586206897| 75.06896551724138|\n",
      "|Middle East and N...|              77.6| 78.10526315789474| 76.42105263157895|\n",
      "|        Eastern Asia|              64.5| 67.16666666666667|             71.25|\n",
      "|Latin America and...| 46.90909090909091|48.333333333333336| 50.77272727272727|\n",
      "|      Western Europe|29.523809523809526| 29.19047619047619|27.142857142857142|\n",
      "|       North America|              10.0|               9.5|              10.5|\n",
      "|Australia and New...|               9.5|               8.5|               9.0|\n",
      "|       Not_Available|               0.0|               0.0|              52.0|\n",
      "+--------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#It will show the ranking of the happiest continents which is based on the mean calculated for each year on groupby continents.\n",
    "Continent_Ranking.select(['Continent','Mean_HR_2015','Mean_HR_2016','Mean_HR_2017']).sort(desc(\"Mean_HR_2015\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
