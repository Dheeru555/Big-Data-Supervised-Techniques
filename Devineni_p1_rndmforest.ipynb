{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SparkSession is the entry point to Spark SQL. It is the very first object \n",
    "#to create while developing Spark SQL applications.\n",
    "#Used the SparkSession.builder method to create an instance of SparkSession with appName('employee')\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('employee').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the HR_comma_sep.csv file into df dataframe.\n",
    "df = spark.read.csv ('HR_comma_sep.csv', inferSchema=True, header =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It displays the schema of the dataframe df\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the module StringIndexer from subpackage ml.feature\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In first step by using StringIndexer function we are creating an output label 'sal_label' with input 'salary', as we need integer values for performing logistic regression\n",
    "#We are transforming the above result into indexed dataframe and showing the first 10 results.\n",
    "indexer = StringIndexer(inputCol='salary', outputCol='sal_label')\n",
    "indexed = indexer.fit(df).transform(df)\n",
    "indexed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the modules Vectors & VectorAssembler from subpackage ml.linalg & ml.feature\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the columns in the indexed dataframe\n",
    "indexed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By using VectorAsssembler creating features output column with input columns including everything except label column\n",
    "#left and sales column which is not much required for this prediction.\n",
    "assembler = VectorAssembler(inputCols=[ 'satisfaction_level',\n",
    " 'last_evaluation',\n",
    " 'number_project',\n",
    " 'average_montly_hours',\n",
    " 'time_spend_company',\n",
    " 'Work_accident',\n",
    " 'promotion_last_5years',\n",
    " 'sal_label'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the indexed dataframe to the dataframe df1\n",
    "df1 = assembler.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In RandomForest algorithm we need to explicitly declare the label column with which one we have to predict.\n",
    "labelIndexer = StringIndexer().setInputCol(\"left\").setOutputCol(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting and trasforming df1 dataframe into df2 dataframe.\n",
    "df2 = labelIndexer.fit(df1).transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the actual data into traindata & test data which is of 70% & 30%\n",
    "trainingData, testData = df2.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required methods like RandomForestClassifer , Evaluator etc\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the randomforestclassifer with the below hyper-parameters\n",
    "#Gini Impurity, Maximum tree depth of 20, 5 trees in the forest and random number seed of 5043\n",
    "classifier = RandomForestClassifier().setImpurity(\"gini\").setMaxDepth(20).setNumTrees(5).setFeatureSubsetStrategy(\"auto\").setSeed(5043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to fit the classifier on training data.\n",
    "model = classifier.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict diagnoses for the testing data\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows the actual value & predicticted value along with other feature co-relation\n",
    "predictions.select(\"satisfaction_level\", \"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the model with MultiClassification Evaluator with 'Accuracy' metric\n",
    "evaluator = MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing the accuracy of 98%\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the model with BinaryClassification Evaluator with 'prediction' metric\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing the accuracy of ~98%\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the models & predicting which technique works better.\n",
    "I have used two classification models i.e. 'Logistic Regression' & 'Radom Forest Classifer'.\n",
    "For Logistic regression the accuracy is 64%\n",
    "For Random forest classifier  the accuracy is 98%\n",
    "\n",
    "Hence I can say by comparing the obtained accuracy, Random forest classifer technique works better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
